{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAxOctagon Hackathon: Data Gathering\n",
    "### Danielle Medellin, Sally Huang, Stephen Burnett, Pierce Butler, Katherine Lough\n",
    "\n",
    "## Problem Statement\n",
    "With Octagon being in the events business, they are looking for a way for consumers to \"check-in\" contactless onsite at events. Our goal is to build a platform that allows for efficient contact-less check-ins that is both easy and quick for attendees.\n",
    "\n",
    "Due to the recent COVID-19 pandemic, safety precautions at future events are of incredible importance. In order to inform the creation of our product, we wanted to gauge public opinion on attending events related to the sports and entertainment industries in a post-COVID world.\n",
    "\n",
    "## Executive Summary\n",
    "Due to the fact that the COVID-19 pandemic is still ongoing, it was difficult to nail down data to use for this exploration. After much consideration and searching for open data resources, we decided our data could come from the subreddit r/Coronavirus. We collected data using the [Pushshift API](https://github.com/pushshift/api). We collected comments from posts in the r/Coronavirus [subreddit](www.reddit.com/r/coronavirus). Comments from the past 60 days were looked at in an effort to get recent opinions. We queried 16 different key words related to COVID and events to filter the comments that came through.\n",
    "\n",
    "The data collected included the following features: author, body, created_utc, subreddit, permalink, query, and timestamp. More information can be found in the data dictionary below.\n",
    "\n",
    "### Data Dictionary\n",
    "|Feature|Type|Description|\n",
    "|---|:---:|:---|\n",
    "|author|object|Username of the author of the comment|\n",
    "|body|object|Full comment text|\n",
    "|created_utc|integer|Coordinated Universal Time of comment|\n",
    "|subreddit|object|Subreddit where comment was found (Coronavirus)|\n",
    "|permalink|object|Partial link to the original comment|\n",
    "|query|object|Query word that pulled in the comment|\n",
    "|timestamp|datetime|Date of comment (YYYY-MM-DD)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Data Collection Using Pushshift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from Mahdi Shadkam-Farrokhi\n",
    "\n",
    "def query_pushshift(subreddit, query_list, kind = 'comment', day_window = 60): # 30 day\n",
    "    SUBFIELDS = ['author', 'body', 'created_utc', 'subreddit', 'permalink', 'query']\n",
    "    \n",
    "    # establish base url and stem\n",
    "    BASE_URL = f\"https://api.pushshift.io/reddit/search/{kind}\" # also known as the \"API endpoint\" \n",
    "    stem1 = f\"{BASE_URL}?q=\"\n",
    "    stem2 = f\"&subreddit={subreddit}&size=500&after={day_window}d\" # always pulling max of 500\n",
    "    \n",
    "    # instantiate empty list for temp storage\n",
    "    comments = []\n",
    "    \n",
    "    # implement for loop with `time.sleep(2)`\n",
    "    for query in query_list:\n",
    "        URL = \"{}{}{}\".format(stem1, query, stem2)\n",
    "        print(\"Querying from: \" + URL)\n",
    "        response = requests.get(URL)\n",
    "        assert response.status_code == 200\n",
    "        mine = response.json()['data']\n",
    "        df = pd.DataFrame.from_dict(mine)\n",
    "        df['query'] = query\n",
    "        comments.append(df)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # pd.concat storage list\n",
    "    full = pd.concat(comments, sort=False)\n",
    "    \n",
    "    # if submission\n",
    "    if kind == \"comment\":\n",
    "        # select desired columns\n",
    "        full = full[SUBFIELDS]\n",
    "        # drop duplicates\n",
    "        full.drop_duplicates(inplace = True)\n",
    "        \n",
    "\n",
    "    # create `timestamp` column\n",
    "    full['timestamp'] = full[\"created_utc\"].map(dt.date.fromtimestamp)\n",
    "    \n",
    "    print(\"Query Complete!\")    \n",
    "    return full "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will use the Pushshift API to gather comments from specific subreddit pages based on keywords. It is set to look for 500 posts at a time from the past 60 days. We are pulling the following columns: `author`, `body`, `created_utc`, `subreddit`, and `permalink`. Within the function we do some cleaning by dropping any duplicate comments. Lastly, we convert the `created_utc` column into datetime form. A dataframe is created. This function will be repeated for each specific keyword or query word that we are looking for in the comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query list\n",
    "queries = {'event','sports','safe','safety','attend','game','concert','feel','fan','protocols','measures','concern','danger','dangerous','unsafe','social', 'unsafe'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will collect comments from the r/Coronavirus subreddit with any of the words in the query list above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=measures&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=safe&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=game&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=event&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=attend&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=danger&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=dangerous&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=unsafe&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=social&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=concert&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=concern&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=sports&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=protocols&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=fan&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=safety&subreddit=coronavirus&size=500&after=60d\n",
      "Querying from: https://api.pushshift.io/reddit/search/comment?q=feel&subreddit=coronavirus&size=500&after=60d\n",
      "Query Complete!\n"
     ]
    }
   ],
   "source": [
    "# collecting comments\n",
    "events_df = query_pushshift('coronavirus',queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>permalink</th>\n",
       "      <th>query</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrauGeist8888</td>\n",
       "      <td>WTF are you even asking for?  It is self-evide...</td>\n",
       "      <td>1590182777</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/gnuq3s/only_73_of_peop...</td>\n",
       "      <td>measures</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disaster_Area</td>\n",
       "      <td>I'm context it's quite obvious that I was sayi...</td>\n",
       "      <td>1590183249</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/go0p56/potus_has_legal...</td>\n",
       "      <td>measures</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IHeedNealing</td>\n",
       "      <td>Not at all my point or intent. Just a few week...</td>\n",
       "      <td>1590183477</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/gojqi1/daily_discussio...</td>\n",
       "      <td>measures</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Omnitraxus</td>\n",
       "      <td>&amp;gt;One of your aunt's colleagues is a super s...</td>\n",
       "      <td>1590183560</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/go9exo/the_us_records_...</td>\n",
       "      <td>measures</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>srelma</td>\n",
       "      <td>&amp;gt;Were reporting something like 140k deaths ...</td>\n",
       "      <td>1590183767</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/goicek/the_death_toll_...</td>\n",
       "      <td>measures</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VarkingRunesong</td>\n",
       "      <td>It sounds over the top but that’s what we do t...</td>\n",
       "      <td>1590194586</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/gouixw/nc_38_test_posi...</td>\n",
       "      <td>feel</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The_avocado_girl</td>\n",
       "      <td>Same with Illinois-&amp;gt; information and plans ...</td>\n",
       "      <td>1590194670</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/gokm4t/a_majority_of_a...</td>\n",
       "      <td>feel</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>khalifornia420</td>\n",
       "      <td>Agreed. Tbh I think a lot of the people on thi...</td>\n",
       "      <td>1590194698</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/gokm4t/a_majority_of_a...</td>\n",
       "      <td>feel</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ivXtreme</td>\n",
       "      <td>Even the most selfless of people have selfish ...</td>\n",
       "      <td>1590194796</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/gorp06/matthew_mcconau...</td>\n",
       "      <td>feel</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>afreakinchorizo</td>\n",
       "      <td>You've summed up exactly how I feel. The inter...</td>\n",
       "      <td>1590195006</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>/r/Coronavirus/comments/gojqi1/daily_discussio...</td>\n",
       "      <td>feel</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                               body  \\\n",
       "0      GrauGeist8888  WTF are you even asking for?  It is self-evide...   \n",
       "1      Disaster_Area  I'm context it's quite obvious that I was sayi...   \n",
       "2       IHeedNealing  Not at all my point or intent. Just a few week...   \n",
       "3         Omnitraxus  &gt;One of your aunt's colleagues is a super s...   \n",
       "4             srelma  &gt;Were reporting something like 140k deaths ...   \n",
       "..               ...                                                ...   \n",
       "95   VarkingRunesong  It sounds over the top but that’s what we do t...   \n",
       "96  The_avocado_girl  Same with Illinois-&gt; information and plans ...   \n",
       "97    khalifornia420  Agreed. Tbh I think a lot of the people on thi...   \n",
       "98          ivXtreme  Even the most selfless of people have selfish ...   \n",
       "99   afreakinchorizo  You've summed up exactly how I feel. The inter...   \n",
       "\n",
       "    created_utc    subreddit  \\\n",
       "0    1590182777  Coronavirus   \n",
       "1    1590183249  Coronavirus   \n",
       "2    1590183477  Coronavirus   \n",
       "3    1590183560  Coronavirus   \n",
       "4    1590183767  Coronavirus   \n",
       "..          ...          ...   \n",
       "95   1590194586  Coronavirus   \n",
       "96   1590194670  Coronavirus   \n",
       "97   1590194698  Coronavirus   \n",
       "98   1590194796  Coronavirus   \n",
       "99   1590195006  Coronavirus   \n",
       "\n",
       "                                            permalink     query   timestamp  \n",
       "0   /r/Coronavirus/comments/gnuq3s/only_73_of_peop...  measures  2020-05-22  \n",
       "1   /r/Coronavirus/comments/go0p56/potus_has_legal...  measures  2020-05-22  \n",
       "2   /r/Coronavirus/comments/gojqi1/daily_discussio...  measures  2020-05-22  \n",
       "3   /r/Coronavirus/comments/go9exo/the_us_records_...  measures  2020-05-22  \n",
       "4   /r/Coronavirus/comments/goicek/the_death_toll_...  measures  2020-05-22  \n",
       "..                                                ...       ...         ...  \n",
       "95  /r/Coronavirus/comments/gouixw/nc_38_test_posi...      feel  2020-05-22  \n",
       "96  /r/Coronavirus/comments/gokm4t/a_majority_of_a...      feel  2020-05-22  \n",
       "97  /r/Coronavirus/comments/gokm4t/a_majority_of_a...      feel  2020-05-22  \n",
       "98  /r/Coronavirus/comments/gorp06/matthew_mcconau...      feel  2020-05-22  \n",
       "99  /r/Coronavirus/comments/gojqi1/daily_discussio...      feel  2020-05-22  \n",
       "\n",
       "[1600 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataframe\n",
    "events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully collected 1600 comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to CSV \n",
    "events_df.to_csv('./data/events_reddit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to the next notebook [`hackathon_analysis`](./hackathon_analysis.ipynb) for analysis of these comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
